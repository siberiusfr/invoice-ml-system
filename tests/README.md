# ğŸ§ª Tests

Tests unitaires et d'intÃ©gration pour le systÃ¨me Invoice ML.

## ğŸ“‹ Structure

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_api.py          # Tests de l'API REST
â”œâ”€â”€ test_models.py       # Tests des modÃ¨les Pydantic
â””â”€â”€ README.md            # Ce fichier
```

## ğŸš€ Lancer les tests

### Tous les tests

```bash
pytest tests/ -v
```

### Tests spÃ©cifiques

```bash
# Tests de l'API
pytest tests/test_api.py -v

# Tests des modÃ¨les
pytest tests/test_models.py -v
```

### Avec couverture

```bash
pytest tests/ --cov=api --cov=training --cov-report=html
```

Le rapport de couverture sera gÃ©nÃ©rÃ© dans `htmlcov/index.html`

## ğŸ“Š Tests disponibles

### test_api.py

Tests de l'API FastAPI:
- âœ… Endpoint racine (/)
- âœ… Health check (/health)
- âœ… Statistiques (/stats)
- âœ… Extraction (/extract)
- â­ï¸ Tests avec modÃ¨le chargÃ© (skip si pas de modÃ¨le)

### test_models.py

Tests des modÃ¨les Pydantic:
- âœ… BoundingBox
- âœ… ExtractedField
- âœ… InvoiceExtraction
- âœ… ExtractionResponse
- âœ… HealthResponse
- âœ… StatsResponse

## ğŸ”§ Configuration

### Installer les dÃ©pendances de test

```bash
pip install pytest pytest-cov
```

### Fixtures

Les fixtures sont dÃ©finies dans `conftest.py` (Ã  crÃ©er si nÃ©cessaire).

## ğŸ“ Ã‰crire de nouveaux tests

### Template de test

```python
import pytest

def test_my_function():
    """Test de ma fonction"""
    # Arrange
    input_data = "test"

    # Act
    result = my_function(input_data)

    # Assert
    assert result == "expected"
```

### Tests avec fixtures

```python
@pytest.fixture
def sample_invoice():
    """Fixture pour une facture de test"""
    return {
        "filename": "test.pdf",
        "fields": [...]
    }

def test_with_fixture(sample_invoice):
    """Test utilisant une fixture"""
    assert sample_invoice["filename"] == "test.pdf"
```

### Tests paramÃ©trÃ©s

```python
@pytest.mark.parametrize("input,expected", [
    (0.5, True),
    (0.3, False),
    (0.9, True)
])
def test_threshold(input, expected):
    """Test avec plusieurs valeurs"""
    result = is_above_threshold(input, 0.5)
    assert result == expected
```

## ğŸ¯ Objectifs de couverture

| Module | Cible | Actuel |
|--------|-------|--------|
| api/ | 80% | TODO |
| training/ | 70% | TODO |
| scripts/ | 60% | TODO |

## ğŸ› Tests d'intÃ©gration

### Test complet du workflow

```bash
# 1. Lancer Label Studio
docker-compose up -d

# 2. Lancer les tests d'intÃ©gration
pytest tests/integration/ -v
```

## ğŸ” Debugging

### Mode verbose

```bash
pytest tests/ -vv
```

### ArrÃªter au premier Ã©chec

```bash
pytest tests/ -x
```

### Afficher les print()

```bash
pytest tests/ -s
```

### Lancer un test spÃ©cifique

```bash
pytest tests/test_api.py::test_root -v
```

## ğŸ“Š CI/CD

### GitHub Actions (exemple)

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
      - name: Run tests
        run: pytest tests/ --cov
```

## ğŸ†˜ ProblÃ¨mes courants

### Import errors

```bash
# Ajouter le projet au PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:."
pytest tests/
```

### Tests qui skip

Les tests peuvent skip pour diffÃ©rentes raisons:
- ModÃ¨le non disponible
- Label Studio non lancÃ©
- DonnÃ©es de test manquantes

VÃ©rifier les messages avec `-v`

## ğŸ“š Ressources

- [pytest documentation](https://docs.pytest.org/)
- [FastAPI testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [Test coverage](https://coverage.readthedocs.io/)

---

**DerniÃ¨re mise Ã  jour:** 2024-01-15

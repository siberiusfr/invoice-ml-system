#!/usr/bin/env python3
"""
Script de r√©entra√Ænement automatique

V√©rifie s'il y a assez de nouvelles annotations et r√©entra√Æne le mod√®le automatiquement.

Usage:
    python scripts/auto_retrain.py
    python scripts/auto_retrain.py --dry-run  # Test sans r√©entra√Æner
"""

import os
import json
import yaml
import argparse
from pathlib import Path
from datetime import datetime
import subprocess

# Couleurs
class Colors:
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BLUE = '\033[94m'
    RESET = '\033[0m'


def load_config():
    """Charger la configuration"""
    config_path = Path(__file__).parent.parent / 'config' / 'settings.yaml'
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def get_latest_export() -> dict:
    """R√©cup√©rer le dernier export d'annotations"""
    exports_dir = Path('data/exports')
    if not exports_dir.exists():
        return None

    export_files = list(exports_dir.glob('annotations_*.json'))
    if not export_files:
        return None

    latest_export = max(export_files, key=os.path.getctime)
    with open(latest_export, 'r') as f:
        return json.load(f)


def get_last_training_info() -> dict:
    """R√©cup√©rer les informations du dernier entra√Ænement"""
    training_log = Path('data/models/training_log.json')

    if not training_log.exists():
        return {
            'last_training_date': None,
            'samples_used': 0,
            'model_path': None
        }

    with open(training_log, 'r') as f:
        return json.load(f)


def save_training_info(samples_count: int, model_path: str):
    """Sauvegarder les informations d'entra√Ænement"""
    training_log = Path('data/models/training_log.json')
    training_log.parent.mkdir(parents=True, exist_ok=True)

    info = {
        'last_training_date': datetime.now().isoformat(),
        'samples_used': samples_count,
        'model_path': model_path
    }

    with open(training_log, 'w') as f:
        json.dump(info, f, indent=2)


def check_if_retrain_needed(config: dict) -> tuple:
    """
    V√©rifier si un r√©entra√Ænement est n√©cessaire

    Returns:
        (needs_retrain, reason, new_samples_count)
    """
    # R√©cup√©rer les donn√©es actuelles
    export_data = get_latest_export()
    if not export_data:
        return False, "Aucun export d'annotations trouv√©", 0

    current_samples = export_data.get('completed_tasks', 0)

    # R√©cup√©rer les infos du dernier entra√Ænement
    last_training = get_last_training_info()
    previous_samples = last_training.get('samples_used', 0)

    # Calculer les nouvelles annotations
    new_samples = current_samples - previous_samples

    # Seuil minimum
    min_new_samples = config['training']['min_new_samples']

    if new_samples >= min_new_samples:
        return True, f"{new_samples} nouvelles annotations (seuil: {min_new_samples})", new_samples
    else:
        return False, f"Seulement {new_samples} nouvelles annotations (seuil: {min_new_samples})", new_samples


def run_training_pipeline(config: dict, dry_run: bool = False):
    """Ex√©cuter le pipeline complet d'entra√Ænement"""

    print(f"\n{Colors.BLUE}{'='*60}{Colors.RESET}")
    print(f"{Colors.BLUE}üîÑ R√âENTRA√éNEMENT AUTOMATIQUE{Colors.RESET}")
    print(f"{Colors.BLUE}{'='*60}{Colors.RESET}\n")

    if dry_run:
        print(f"{Colors.YELLOW}üß™ MODE TEST (dry-run) - Aucun entra√Ænement ne sera effectu√©{Colors.RESET}\n")

    # V√©rifier si un r√©entra√Ænement est n√©cessaire
    needs_retrain, reason, new_samples = check_if_retrain_needed(config)

    print(f"{Colors.YELLOW}üìä √âtat actuel:{Colors.RESET}")
    print(f"   {reason}\n")

    if not needs_retrain:
        print(f"{Colors.YELLOW}‚è∏Ô∏è  R√©entra√Ænement non n√©cessaire pour le moment{Colors.RESET}\n")
        return

    print(f"{Colors.GREEN}‚úÖ R√©entra√Ænement n√©cessaire !{Colors.RESET}\n")

    if dry_run:
        print(f"{Colors.YELLOW}Mode test activ√© - Les √©tapes suivantes seraient ex√©cut√©es:{Colors.RESET}")
        print(f"   1. Export depuis Label Studio")
        print(f"   2. Pr√©paration du dataset")
        print(f"   3. Entra√Ænement du mod√®le")
        print(f"   4. √âvaluation")
        print(f"   5. Sauvegarde des informations")
        return

    # √âtape 1: Exporter depuis Label Studio
    print(f"{Colors.YELLOW}üì§ √âtape 1/4: Export depuis Label Studio...{Colors.RESET}")
    try:
        result = subprocess.run(
            ['python', 'scripts/export_from_label_studio.py'],
            check=True,
            capture_output=True,
            text=True
        )
        print(f"{Colors.GREEN}‚úÖ Export termin√©{Colors.RESET}\n")
    except subprocess.CalledProcessError as e:
        print(f"{Colors.RED}‚ùå Erreur lors de l'export: {e}{Colors.RESET}")
        return

    # √âtape 2: Pr√©parer le dataset
    print(f"{Colors.YELLOW}üì¶ √âtape 2/4: Pr√©paration du dataset...{Colors.RESET}")
    try:
        result = subprocess.run(
            ['python', 'scripts/prepare_dataset.py'],
            check=True,
            capture_output=True,
            text=True
        )
        print(f"{Colors.GREEN}‚úÖ Dataset pr√©par√©{Colors.RESET}\n")
    except subprocess.CalledProcessError as e:
        print(f"{Colors.RED}‚ùå Erreur lors de la pr√©paration: {e}{Colors.RESET}")
        return

    # √âtape 3: Entra√Æner le mod√®le
    print(f"{Colors.YELLOW}ü§ñ √âtape 3/4: Entra√Ænement du mod√®le...{Colors.RESET}")
    try:
        result = subprocess.run(
            ['python', 'training/train_yolo.py'],
            check=True,
            capture_output=True,
            text=True
        )
        print(f"{Colors.GREEN}‚úÖ Entra√Ænement termin√©{Colors.RESET}\n")
    except subprocess.CalledProcessError as e:
        print(f"{Colors.RED}‚ùå Erreur lors de l'entra√Ænement: {e}{Colors.RESET}")
        return

    # √âtape 4: √âvaluer le mod√®le
    print(f"{Colors.YELLOW}üìä √âtape 4/4: √âvaluation du mod√®le...{Colors.RESET}")
    try:
        result = subprocess.run(
            ['python', 'training/evaluate.py'],
            check=True,
            capture_output=True,
            text=True
        )
        print(f"{Colors.GREEN}‚úÖ √âvaluation termin√©e{Colors.RESET}\n")
    except subprocess.CalledProcessError as e:
        print(f"{Colors.RED}‚ùå Erreur lors de l'√©valuation: {e}{Colors.RESET}")
        # Continuer m√™me si l'√©valuation √©choue

    # Sauvegarder les informations
    export_data = get_latest_export()
    save_training_info(
        samples_count=export_data.get('completed_tasks', 0),
        model_path="data/models/latest"
    )

    print(f"{Colors.BLUE}{'='*60}{Colors.RESET}")
    print(f"{Colors.GREEN}‚ú® R√©entra√Ænement termin√© avec succ√®s !{Colors.RESET}")
    print(f"{Colors.BLUE}{'='*60}{Colors.RESET}\n")


def main():
    """Main"""
    parser = argparse.ArgumentParser(description="R√©entra√Ænement automatique")
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Mode test - v√©rifie sans r√©entra√Æner'
    )
    args = parser.parse_args()

    config = load_config()

    if not config['auto_retrain']['enabled'] and not args.dry_run:
        print(f"{Colors.YELLOW}‚ö†Ô∏è  R√©entra√Ænement automatique d√©sactiv√© dans la configuration{Colors.RESET}")
        print(f"{Colors.YELLOW}üí° Activez-le dans config/settings.yaml ou utilisez --dry-run{Colors.RESET}")
        return

    run_training_pipeline(config, dry_run=args.dry_run)


if __name__ == '__main__':
    main()
